# 计算机视觉

# 一、概述

计算机视觉的四个主要任务：**分类、定位、检测、分割**。
需要解决的困难：
**语义鸿沟(semantic gap)** 人类可以轻松地从图像中识别出目标，而计算机看到的图像只是一组0到255之间的整数。
**计算机视觉任务的其他困难** 拍摄视角变化、目标占据图像的比例变化、光照变化、背景融合、目标形变、遮挡等。
![image-20210412103457507](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210412103457507.png)

# 二、各个模块

## U-2-NET(分割)

1.U-2-NET功能: 语义分割
2.网络结构: ![U2NETPR](D:\fwwbA02\U-2-Net\U-2-Net-master\U2NETPR.png)
3.网络详情: 
（待更新）

## RCNN系列

1.两阶段过程：区域选择+检测（分类+定位）

2.RCNN

![image-20210515190525970](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515190525970.png)

3.Fast-RCNN

![image-20210515190858493](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515190858493.png)

RCNN采用滑窗方式和selective search产生了大量的候选区域（region proposals或regions of interest，aka ROI），计算量大，Fast-RCNN解决了RCNN对候选区域重复提取特征的问题，采用ROI Polling。

ROI Polling：

1）操作

根据输入image，将ROI映射到feature map对应位置；

将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）；

对每个sections进行max pooling操作；

输出的feature maps的大小不取决于ROI和卷积feature maps大小

2）示例

![image-20210515192120742](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515192120742.png)

![image-20210515192143037](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515192143037.png)

![image-20210515192202264](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515192202264.png)

4.Faster-RCNN

采用了Region Proposal Network（RPN）

![image-20210515190933952](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515190933952.png)

RPN网络：

1）锚框（Anchor Boxe）

![image-20210515202812001](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210515202812001.png)

## Yolo(检测)

1.关联: RCNN/Fast RCNN/Faster RCNN均可用于目标检测, RCNN系列开创性的提
出了候选区(Region Proposals)的方法, 先从图片中搜索出一些可能存在对象的候
选区Selective Search, 大概2000个左右, 然后对每个候选区进行对象识别.

2.**YOLO创造性的将候选区和对象识别这两个阶段合二为一**, 看一眼图片就能知道
有哪些对象以及它们的位置。实际上, **YOLO并没有真正去掉候选区, 而是采用了预**
**定义的候选区**(准确说应该是预测区，并不是Faster RCNN所采用的Anchor). 也
就是将图片划分为 7*7=49 个网格(grid), 每个网格允许预测出2个边框(bounding *
*box，包含某个对象的矩形框), 总共 49*2=98 个bounding box. 可以理解为98个候
选区, 它们很粗略的覆盖了图片的整个区域.
![image-20210424222008749](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210424222008749.png)

## PP-Yolo

1.PPYolo的改进

![image-20210513212829810](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210513212829810.png)

# 三、总结及综述

## 1.过拟合与Dropout

过拟合：
如果模型的参数太多，而训练样本又太少，训练出来的模型很容易产生过拟合的现象。在训练神经网络的时候经常会遇到过拟合的问题，过拟合具体表现在：模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。
过拟合是很多机器学习的通病。如果模型过拟合，那么得到的模型几乎不能用。为了解决过拟合问题，一般会采用模型集成的方法，即训练多个模型进行组合。此时，训练模型费时就成为一个很大的问题，不仅训练多个模型费时，测试多个模型也是很费时。
Dropout：
Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。
在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。
Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征
![20180619185225799](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\20180619185225799.png)

## 2.神经网络中各个层的作用

（1）卷积层：进行特征提取，得到的特征图通常会改变原图的尺寸（1×1卷积除外，1×1卷积的作用相当于把原图的各个通道乘以系数后联系在一起），但不改变通道数。
权值共享：同一个卷积核扫描处理的区域所用的权值系数相同，及权值共享
![1062917-20161117200716201-1820175673](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1062917-20161117200716201-1820175673.png)
（2）池化层：
1）作用：降维，减少网络要学习的参数数量；防止过拟合；扩大感受野；进行特征压缩，提取主要特征；实现不变性（平移、旋转、尺度不变性）；
2）池化层会减小尺寸，一般不会改变通道数；
3）池化一般紧跟在卷积层后；
4）插播注意：池化操作包含于下采样操作；
缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：1、使得图像符合显示区域的大小；2、生成对应图像的缩略图。
放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像,从而可以显示在更高分辨率的显示设备上。
上采样原理：图像放大几乎都是采用内插值方法，即在原有图像像素的基础上在像素点之间采用合适的插值算法插入新的元素。
双线性插值具有平滑功能，高阶插值（如双三次和三次样条插值）使插值生成的像素灰度值延续原图像灰度变化的连续性，更加平滑。但是在图像中本就存在灰度值突变，在上采样过程中会影响图片质量。
5）池化操作一般分为两种，平均池化（average pooling）以及最大池化（max pooling）；
max_pooling： 夜晚的地球俯瞰图，灯光耀眼的穿透性让人们只注意到最max的部分，产生亮光区域被放大的视觉错觉。故而 max_pooling 对较抽象一点的特征（如纹理）提取更好。
average_pooling： 白天的地球俯瞰图，幅员辽阔的地球表面，仿佛被经过了二次插值的缩小，所有看到的都是像素点取平均的结果。故而 average_pooling 对较形象的特征（如背景信息)保留更好。

## 3.匈牙利算法

**匈牙利算法**是一种在多项式时间内求解任务分配问题的组合优化算法，并推动了后来的原始对偶方法。
二分图：![image-20210529170924424](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210529170924424.png)
匈牙利算法就是为二分图中的每一个点进行匹配的算法。
匈牙利算法在MOT中的应用：可以把二分图理解为视频中连续两帧中的所有检测框，第一帧所有检测框的集合称为U，第二帧所有检测框的集合称为V。同一帧的不同检测框不会为同一个目标，所以不需要互相关联，相邻两帧的检测框需要相互联通，最终将相邻两帧的检测框尽量完美地两两匹配起来。而求解这个问题的最优解就要用到匈牙利算法或者KM算法。

## VOC和COCO数据集介绍

#### 1. voc格式数介绍

VOC数据格式的目标检测数据，是指每个图像文件对应一个同名的xml文件，xml文件中标记物体框的坐标和类别等信息。
Pascal VOC比赛对目标检测任务，对目标物体是否遮挡、是否被截断、是否是难检测物体进行了标注。对于用户自定义数据可根据实际情况对这些字段进行标注。
xml文件中包含以下字段：

- filename字段，表示图像名称。
```
<filename>road650.png</filename>
```
- size字段，表示图像尺寸。包括：图像宽度、图像高度、图像深度
```
<size>
	<width>300</width>
	<height>400</height>
	<depth>3</depth>
</size>
```
- object字段，表示每个物体。包括
  - `name`: 目标物体类别名称
  - `pose`: 关于目标物体姿态描述（非必须字段）
  - `truncated`: 目标物体目标因为各种原因被截断（非必须字段）
  - `occluded`: 目标物体是否被遮挡（非必须字段）
  - `difficult`: 目标物体是否是很难识别（非必须字段）
  - `bndbox`: 物体位置坐标，用左上角坐标和右下角坐标表示：`xmin`、`ymin`、`xmax`、`ymax`

#### 2. coco格式数介绍

coco数据格式，是指将所有训练图像的标注都存放到一个.json文件中。数据以字典嵌套的形式存放。
.json文件中存放了 `info licenses images annotations categories`的信息:

- info中存放标注文件标注时间、版本等信息。
- licenses中存放数据许可信息。
- images中存放一个list，存放所有图像的图像名，下载地址，图像宽度，图像高度，图像在数据集中的id等信息。
- annotations中存放一个list，存放所有图像的所有物体区域的标注信息，每个目标物体标注以下信息：

```
    {
    	'area': 899, 
    	'iscrowd': 0, 
        'image_id': 839, 
        'bbox': [114, 126, 31, 29], 
        'category_id': 0, 'id': 1, 
        'ignore': 0, 
        'segmentation': []
    }
```
